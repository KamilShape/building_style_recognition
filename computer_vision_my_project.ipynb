{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLck826s2V6ZR9HffJoLCY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamilShape/building_style_recognition/blob/main/computer_vision_my_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "pOcy-dV0hrtu"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connecting to google drive"
      ],
      "metadata": {
        "id": "iB8CWIiB_xj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTXJhcKp_2Q7",
        "outputId": "4093e270-065e-41c7-ed36-a03a278c18fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Images"
      ],
      "metadata": {
        "id": "asgOrPg4g_Rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "styles = ['greek-architecture', 'gothic-architecture', 'baroque-architecture', 'victorian-architecture', 'modern architecture']"
      ],
      "metadata": {
        "id": "RvTWfqf6whjy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_url(content):\n",
        "  soup = BeautifulSoup(content, 'html.parser')\n",
        "  imgs = soup.find_all('img', {'class': 'grid-image'})\n",
        "  return [img['src'] for img in imgs]"
      ],
      "metadata": {
        "id": "S5FxZwHfTLgu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = f'https://www.freeimages.com/search'\n",
        "def get_page(url,style, page):\n",
        "  for page in range(1, page + 1):\n",
        "    url = url + f'/{style}/{page}'\n",
        "    try:\n",
        "      response = requests.get(url)\n",
        "      content = response.content\n",
        "      return content\n",
        "    except:\n",
        "      print('Error! Wrong url.')"
      ],
      "metadata": {
        "id": "VzdRb7cjJHBR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image(photo_url, path, file_name, style):\n",
        "  image_response = requests.get(photo_url)\n",
        "  image_content = image_response.content\n",
        "  img = Image.open(BytesIO(image_content))\n",
        "  if img.mode == 'RGB':\n",
        "    os.makedirs(f'{path}/{style}', exist_ok=True)\n",
        "    img.save(f'{path}/{style}/{file_name}', 'png')"
      ],
      "metadata": {
        "id": "3U19Jh_KULat"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = 'drive/MyDrive/architecture_photos/data/train'"
      ],
      "metadata": {
        "id": "CdoRW2NFLt8p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_photos(style, page, path):\n",
        "  content = get_page(style, page)\n",
        "  images = parse_url(content)\n",
        "  for image in images:\n",
        "    if len(image) > 5:\n",
        "      file_name = image.split('/')[-1]\n",
        "      get_image(image, train_path, file_name, style)\n"
      ],
      "metadata": {
        "id": "_fvJULIfLAMk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DOWNLOADING ALL PHOTOS\n",
        "for style in styles:\n",
        "  get_photos(style, 10, train_path)"
      ],
      "metadata": {
        "id": "a7vfIKfKMwuv"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test and train data sets"
      ],
      "metadata": {
        "id": "WYTn-dWl8Sx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = 'drive/MyDrive/architecture_photos/data/test'"
      ],
      "metadata": {
        "id": "e9xptSeJaT3F"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(f'{test_path}')"
      ],
      "metadata": {
        "id": "kQMrM4gs9neC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_test_set(styles, train_path, test_path, set_size):\n",
        "  for style in styles:\n",
        "    files_folder = os.listdir(f'{train_path}/{style}')\n",
        "    for n in range(0, round(len(files_folder)*set_size)+1):\n",
        "      files_folder = os.listdir(f'{train_path}/{style}')\n",
        "      photo_number = np.random.randint(len(files_folder))\n",
        "      os.makedirs(f'{test_path}/{style}', exist_ok=True)\n",
        "      os.replace(f'{train_path}/{style}/{files_folder[photo_number]}', f'{test_path}/{style}/{files_folder[photo_number]}')"
      ],
      "metadata": {
        "id": "i0gntixDMWRQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_test_set(styles, train_path, test_path, 0.15)"
      ],
      "metadata": {
        "id": "bevPviRJ8cQi"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model "
      ],
      "metadata": {
        "id": "BYnt8poeiGTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "kqbGuKcYjPAS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 64\n",
        "img_width = 64\n",
        "batch_size = 30"
      ],
      "metadata": {
        "id": "9QNowU9LiZVZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    train_path,\n",
        "    validation_split = 0.2,\n",
        "    seed=0,\n",
        "    subset='training',\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical')\n",
        "\n",
        "val_ds = keras.utils.image_dataset_from_directory(\n",
        "    train_path,\n",
        "    validation_split = 0.5,\n",
        "    seed=0,\n",
        "    subset='validation',\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap_J-rIDinCe",
        "outputId": "b2bae856-84b9-4f8d-c3c6-f1b0d5f8ed81"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 244 files belonging to 5 classes.\n",
            "Using 196 files for training.\n",
            "Found 244 files belonging to 5 classes.\n",
            "Using 122 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Rescaling(1./255))\n",
        "model.add(layers.Conv2D(64, (4,4), padding='same', activation='relu'))\n",
        "model.add(layers.MaxPool2D((2,2)))\n",
        "model.add(layers.Conv2D(32, (4,4), padding='same', activation='relu'))\n",
        "model.add(layers.MaxPool2D((2,2)))\n",
        "model.add(layers.Conv2D(16, (4,4), padding='same', activation='relu'))\n",
        "model.add(layers.MaxPool2D((2,2)))\n",
        "model.add(layers.Conv2D(8, (4,4), padding='same', activation='relu'))\n",
        "model.add(layers.MaxPool2D((2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(5, activation='softmax'))"
      ],
      "metadata": {
        "id": "XXxlNZ73jINb"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "SDhzQcoyktI8"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = 30,\n",
        "    batch_size = batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alSTJAjmkul6",
        "outputId": "d76eb288-7019-41e4-9a4a-d8245ba2d32e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "7/7 [==============================] - 5s 665ms/step - loss: 0.9679 - accuracy: 0.6020 - val_loss: 1.2124 - val_accuracy: 0.5984\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - 4s 546ms/step - loss: 0.9242 - accuracy: 0.6531 - val_loss: 1.2065 - val_accuracy: 0.5738\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - 4s 567ms/step - loss: 0.8497 - accuracy: 0.7296 - val_loss: 1.1430 - val_accuracy: 0.6148\n",
            "Epoch 4/30\n",
            "7/7 [==============================] - 5s 776ms/step - loss: 0.8705 - accuracy: 0.6684 - val_loss: 1.3079 - val_accuracy: 0.5164\n",
            "Epoch 5/30\n",
            "7/7 [==============================] - 4s 584ms/step - loss: 0.8176 - accuracy: 0.6684 - val_loss: 1.1515 - val_accuracy: 0.6148\n",
            "Epoch 6/30\n",
            "7/7 [==============================] - 4s 532ms/step - loss: 0.7530 - accuracy: 0.7092 - val_loss: 1.2996 - val_accuracy: 0.5738\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - 5s 662ms/step - loss: 0.7676 - accuracy: 0.7551 - val_loss: 1.2271 - val_accuracy: 0.5820\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - 5s 747ms/step - loss: 0.7166 - accuracy: 0.7449 - val_loss: 1.3132 - val_accuracy: 0.6230\n",
            "Epoch 9/30\n",
            "7/7 [==============================] - 4s 549ms/step - loss: 0.6357 - accuracy: 0.7806 - val_loss: 1.1360 - val_accuracy: 0.6393\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - 5s 713ms/step - loss: 0.5695 - accuracy: 0.8061 - val_loss: 1.2064 - val_accuracy: 0.6230\n",
            "Epoch 11/30\n",
            "7/7 [==============================] - 5s 657ms/step - loss: 0.5503 - accuracy: 0.7857 - val_loss: 1.1199 - val_accuracy: 0.6557\n",
            "Epoch 12/30\n",
            "7/7 [==============================] - 5s 618ms/step - loss: 0.4658 - accuracy: 0.8724 - val_loss: 1.2494 - val_accuracy: 0.6393\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - 4s 525ms/step - loss: 0.4386 - accuracy: 0.8673 - val_loss: 1.1001 - val_accuracy: 0.6885\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - 5s 750ms/step - loss: 0.3554 - accuracy: 0.8929 - val_loss: 1.1711 - val_accuracy: 0.6967\n",
            "Epoch 15/30\n",
            "7/7 [==============================] - 4s 568ms/step - loss: 0.3260 - accuracy: 0.9031 - val_loss: 1.1475 - val_accuracy: 0.6639\n",
            "Epoch 16/30\n",
            "7/7 [==============================] - 6s 790ms/step - loss: 0.2897 - accuracy: 0.9082 - val_loss: 1.2400 - val_accuracy: 0.6967\n",
            "Epoch 17/30\n",
            "7/7 [==============================] - 4s 574ms/step - loss: 0.2556 - accuracy: 0.9490 - val_loss: 1.1546 - val_accuracy: 0.7131\n",
            "Epoch 18/30\n",
            "7/7 [==============================] - 4s 551ms/step - loss: 0.2376 - accuracy: 0.9490 - val_loss: 1.2364 - val_accuracy: 0.7049\n",
            "Epoch 19/30\n",
            "7/7 [==============================] - 6s 695ms/step - loss: 0.1932 - accuracy: 0.9592 - val_loss: 1.2254 - val_accuracy: 0.7213\n",
            "Epoch 20/30\n",
            "7/7 [==============================] - 5s 712ms/step - loss: 0.1624 - accuracy: 0.9592 - val_loss: 1.2701 - val_accuracy: 0.7213\n",
            "Epoch 21/30\n",
            "7/7 [==============================] - 4s 530ms/step - loss: 0.1348 - accuracy: 0.9796 - val_loss: 1.3168 - val_accuracy: 0.7213\n",
            "Epoch 22/30\n",
            "7/7 [==============================] - 4s 540ms/step - loss: 0.1156 - accuracy: 0.9796 - val_loss: 1.3749 - val_accuracy: 0.7131\n",
            "Epoch 23/30\n",
            "7/7 [==============================] - 5s 663ms/step - loss: 0.1436 - accuracy: 0.9592 - val_loss: 1.6174 - val_accuracy: 0.6639\n",
            "Epoch 24/30\n",
            "7/7 [==============================] - 5s 538ms/step - loss: 0.1742 - accuracy: 0.9490 - val_loss: 1.5281 - val_accuracy: 0.7049\n",
            "Epoch 25/30\n",
            "7/7 [==============================] - 4s 536ms/step - loss: 0.1040 - accuracy: 0.9898 - val_loss: 1.4536 - val_accuracy: 0.7295\n",
            "Epoch 26/30\n",
            "7/7 [==============================] - 5s 774ms/step - loss: 0.0933 - accuracy: 0.9898 - val_loss: 1.3894 - val_accuracy: 0.7459\n",
            "Epoch 27/30\n",
            "7/7 [==============================] - 4s 558ms/step - loss: 0.0650 - accuracy: 0.9949 - val_loss: 1.4099 - val_accuracy: 0.7377\n",
            "Epoch 28/30\n",
            "7/7 [==============================] - 6s 737ms/step - loss: 0.0701 - accuracy: 0.9949 - val_loss: 1.4592 - val_accuracy: 0.7377\n",
            "Epoch 29/30\n",
            "7/7 [==============================] - 4s 551ms/step - loss: 0.0531 - accuracy: 0.9949 - val_loss: 1.4209 - val_accuracy: 0.7295\n",
            "Epoch 30/30\n",
            "7/7 [==============================] - 5s 706ms/step - loss: 0.0777 - accuracy: 0.9847 - val_loss: 1.5126 - val_accuracy: 0.7459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lyw2tL6LIu6-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}